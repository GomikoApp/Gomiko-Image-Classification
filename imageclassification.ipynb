{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066737a2",
   "metadata": {},
   "source": [
    "# Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe83007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory, image\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853c225",
   "metadata": {},
   "source": [
    "# 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9fdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"dataset\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7ee7b",
   "metadata": {},
   "source": [
    "## 1.1. Split dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0e777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2552 files belonging to 6 classes.\n",
      "Using 2042 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 12:59:58.265669: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_INVALID_PTX'\n",
      "\n",
      "2025-08-28 12:59:58.265705: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2025-08-28 12:59:58.265715: W tensorflow/core/framework/op_kernel.cc:1842] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "2025-08-28 12:59:58.265721: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "{{function_node __wrapped__Equal_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Equal] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_ds = \u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/keras/src/utils/image_dataset_utils.py:334\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    330\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m dataset = \u001b[43mpaths_and_labels_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrop_to_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrop_to_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle_buffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle_buffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    351\u001b[39m     dataset = dataset.batch(batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/keras/src/utils/image_dataset_utils.py:389\u001b[39m, in \u001b[36mpaths_and_labels_to_dataset\u001b[39m\u001b[34m(image_paths, image_size, num_channels, labels, label_mode, num_classes, interpolation, data_format, crop_to_aspect_ratio, pad_to_aspect_ratio, shuffle, shuffle_buffer_size, seed)\u001b[39m\n\u001b[32m    386\u001b[39m     ds = path_ds\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     ds = \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle_buffer_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m args = (\n\u001b[32m    392\u001b[39m     image_size,\n\u001b[32m    393\u001b[39m     num_channels,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     pad_to_aspect_ratio,\n\u001b[32m    398\u001b[39m )\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:1510\u001b[39m, in \u001b[36mDatasetV2.shuffle\u001b[39m\u001b[34m(self, buffer_size, seed, reshuffle_each_iteration, name)\u001b[39m\n\u001b[32m   1419\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshuffle\u001b[39m(\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28mself\u001b[39m, buffer_size, seed=\u001b[38;5;28;01mNone\u001b[39;00m, reshuffle_each_iteration=\u001b[38;5;28;01mTrue\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1421\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mDatasetV2\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1422\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Randomly shuffles the elements of this dataset.\u001b[39;00m\n\u001b[32m   1423\u001b[39m \n\u001b[32m   1424\u001b[39m \u001b[33;03m  This dataset fills a buffer with `buffer_size` elements, then randomly\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1508\u001b[39m \u001b[33;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[32m   1509\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1510\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshuffle_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_shuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m   1511\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshuffle_each_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/tensorflow/python/data/ops/shuffle_op.py:32\u001b[39m, in \u001b[36m_shuffle\u001b[39m\u001b[34m(input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_shuffle\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[32m     26\u001b[39m     input_dataset,\n\u001b[32m     27\u001b[39m     buffer_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     name=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     31\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ShuffleDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshuffle_each_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/tensorflow/python/data/ops/shuffle_op.py:51\u001b[39m, in \u001b[36m_ShuffleDataset.__init__\u001b[39m\u001b[34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m._input_dataset = input_dataset\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m._buffer_size = ops.convert_to_tensor(\n\u001b[32m     50\u001b[39m     buffer_size, dtype=dtypes.int64, name=\u001b[33m\"\u001b[39m\u001b[33mbuffer_size\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28mself\u001b[39m._seed, \u001b[38;5;28mself\u001b[39m._seed2 = \u001b[43mrandom_seed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mself\u001b[39m._reshuffle_each_iteration = reshuffle_each_iteration\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/tensorflow/python/data/util/random_seed.py:50\u001b[39m, in \u001b[36mget_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     46\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(\u001b[33m\"\u001b[39m\u001b[33mseed2\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[32m     47\u001b[39m     seed2 = ops.convert_to_tensor(seed2, dtype=dtypes.int64)\n\u001b[32m     48\u001b[39m     seed2 = array_ops.where_v2(\n\u001b[32m     49\u001b[39m         math_ops.logical_and(\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m             \u001b[43mmath_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m, math_ops.equal(seed2, \u001b[32m0\u001b[39m)),\n\u001b[32m     51\u001b[39m         constant_op.constant(\u001b[32m2\u001b[39m**\u001b[32m31\u001b[39m - \u001b[32m1\u001b[39m, dtype=dtypes.int64),\n\u001b[32m     52\u001b[39m         seed2,\n\u001b[32m     53\u001b[39m         name=scope)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m seed, seed2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Gomiko-Image-Classification/tf-env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6027\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6025\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6026\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6027\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInternalError\u001b[39m: {{function_node __wrapped__Equal_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Equal] name: "
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b54605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a60042",
   "metadata": {},
   "source": [
    "## 1.2. Prefetching to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1cd27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88e95d",
   "metadata": {},
   "source": [
    "# 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71885ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a34f94",
   "metadata": {},
   "source": [
    "# 3. Load Pre-trained MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e58084",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(input_shape=img_size + (3,),\n",
    "                         include_top=False,\n",
    "                         weights=\"imagenet\")\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fb176",
   "metadata": {},
   "source": [
    "# 4. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedce638",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=img_size + (3,))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)  # preprocess for MobileNetV2\n",
    "\n",
    "x = base_model(x, training=False)  # no BN updates\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)  # helps prevent overfitting\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513b8d6",
   "metadata": {},
   "source": [
    "# 5. Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4184e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45207717",
   "metadata": {},
   "source": [
    "# 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add early stopping for when val_loss does not improve for a set number of epoch\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dea7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=30,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b6600",
   "metadata": {},
   "source": [
    "# 7. Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:]:  # freeze all but last 40 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         validation_data=val_ds,\n",
    "                         epochs=30,\n",
    "                         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881f0dd",
   "metadata": {},
   "source": [
    "# Show graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(30)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3505e",
   "metadata": {},
   "source": [
    "# Test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c3f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_single_image(img_path, model, class_names, top_k=3):\n",
    "    # load and prepare image (do NOT call preprocess_input here because the model already does it)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)            # shape (224,224,3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # shape (1,224,224,3)\n",
    "\n",
    "    preds = model.predict(img_array)               # model will preprocess internally\n",
    "    probs = preds[0]\n",
    "    top_idx = np.argsort(probs)[-top_k:][::-1]\n",
    "    return [(class_names[i], float(probs[i])) for i in top_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"test/glass-bottle.png\"\n",
    "img_vis = image.load_img(img_path, target_size=(224,224))\n",
    "plt.imshow(img_vis); plt.axis('off'); plt.title(\"Test image\"); plt.show()\n",
    "\n",
    "print(\"Top predictions:\", predict_single_image(img_path, model, class_names, top_k=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
